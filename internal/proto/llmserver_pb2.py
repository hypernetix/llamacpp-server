# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: llmserver.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    5,
    29,
    0,
    '',
    'llmserver.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0fllmserver.proto\x12\x05proto\"\r\n\x0bPingRequest\"\x0e\n\x0cPingResponse\"m\n\x10LoadModelRequest\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\x19\n\x11trust_remote_code\x18\x02 \x01(\x08\x12$\n\x07\x62\x61\x63kend\x18\x03 \x01(\x0e\x32\x0e.proto.BackendH\x00\x88\x01\x01\x42\n\n\x08_backend\"%\n\x11LoadModelResponse\x12\x10\n\x08progress\x18\x01 \x01(\x02\"\"\n\x12UnloadModelRequest\x12\x0c\n\x04path\x18\x01 \x01(\t\"\x15\n\x13UnloadModelResponse\"\x84\x06\n\x0ePredictRequest\x12\r\n\x05model\x18\x01 \x01(\t\x12\x0e\n\x06prompt\x18\x02 \x01(\t\x12\x0e\n\x06stream\x18\x03 \x01(\x08\x12\x12\n\nmax_tokens\x18\x04 \x01(\x05\x12\x13\n\x0btemperature\x18\x05 \x01(\x02\x12\r\n\x05top_p\x18\x06 \x01(\x02\x12\r\n\x05top_k\x18\x07 \x01(\x05\x12.\n\x07options\x18\x08 \x01(\x0b\x32\x1d.proto.PredictRequest.Options\x1a\xcb\x04\n\x07Options\x12\x12\n\x05min_p\x18\x01 \x01(\x02H\x00\x88\x01\x01\x12\x1f\n\x12min_tokens_to_keep\x18\x02 \x01(\x05H\x01\x88\x01\x01\x12\x18\n\x0bmax_kv_size\x18\x03 \x01(\x05H\x02\x88\x01\x01\x12\x1e\n\x11prefill_step_size\x18\x04 \x01(\x05H\x03\x88\x01\x01\x12\x14\n\x07kv_bits\x18\x05 \x01(\x05H\x04\x88\x01\x01\x12\x1a\n\rkv_group_size\x18\x06 \x01(\x05H\x05\x88\x01\x01\x12\x1f\n\x12quantized_kv_start\x18\x07 \x01(\x05H\x06\x88\x01\x01\x12\x1f\n\x12repetition_penalty\x18\x08 \x01(\x02H\x07\x88\x01\x01\x12\x1b\n\x0elength_penalty\x18\t \x01(\x02H\x08\x88\x01\x01\x12\x1e\n\x11\x64iversity_penalty\x18\n \x01(\x02H\t\x88\x01\x01\x12!\n\x14no_repeat_ngram_size\x18\x0b \x01(\x05H\n\x88\x01\x01\x12\x18\n\x0brandom_seed\x18\x0c \x01(\x05H\x0b\x88\x01\x01\x42\x08\n\x06_min_pB\x15\n\x13_min_tokens_to_keepB\x0e\n\x0c_max_kv_sizeB\x14\n\x12_prefill_step_sizeB\n\n\x08_kv_bitsB\x10\n\x0e_kv_group_sizeB\x15\n\x13_quantized_kv_startB\x15\n\x13_repetition_penaltyB\x11\n\x0f_length_penaltyB\x14\n\x12_diversity_penaltyB\x17\n\x15_no_repeat_ngram_sizeB\x0e\n\x0c_random_seed\"A\n\x0fPredictResponse\x12\x0f\n\x07message\x18\x01 \x01(\x0c\x12\r\n\x05token\x18\x02 \x01(\x05\x12\x0e\n\x06tokens\x18\x03 \x01(\x05\"%\n\x15GetModelStatusRequest\x12\x0c\n\x04path\x18\x01 \x01(\t\"\\\n\x16GetModelStatusResponse\x12\x0c\n\x04path\x18\x01 \x01(\t\x12\"\n\x06status\x18\x02 \x01(\x0e\x32\x12.proto.ModelStatus\x12\x10\n\x08progress\x18\x03 \x01(\x02\"\x13\n\x11ListModelsRequest\"\x14\n\x12ListModelsResponse*?\n\x0bModelStatus\x12\x0b\n\x07UNKNOWN\x10\x00\x12\x0b\n\x07LOADING\x10\x01\x12\n\n\x06LOADED\x10\x02\x12\n\n\x06\x46\x41ILED\x10\x03*j\n\x07\x42\x61\x63kend\x12\x17\n\x13\x42\x41\x43KEND_UNSPECIFIED\x10\x00\x12\x15\n\x11\x42\x41\x43KEND_LLAMA_CPP\x10\x01\x12\x0f\n\x0b\x42\x41\x43KEND_MLX\x10\x02\x12\x0e\n\nBACKEND_TF\x10\x03\x12\x0e\n\nBACKEND_PT\x10\x04\x32\xc0\x01\n\tLLMServer\x12\x31\n\x04Ping\x12\x12.proto.PingRequest\x1a\x13.proto.PingResponse\"\x00\x12\x42\n\tLoadModel\x12\x17.proto.LoadModelRequest\x1a\x18.proto.LoadModelResponse\"\x00\x30\x01\x12<\n\x07Predict\x12\x15.proto.PredictRequest\x1a\x16.proto.PredictResponse\"\x00\x30\x01\x42\x38Z6githum.com/hypernetix/localllmtest/llmgrpcserver/protob\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'llmserver_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'Z6githum.com/hypernetix/localllmtest/llmgrpcserver/proto'
  _globals['_MODELSTATUS']._serialized_start=1284
  _globals['_MODELSTATUS']._serialized_end=1347
  _globals['_BACKEND']._serialized_start=1349
  _globals['_BACKEND']._serialized_end=1455
  _globals['_PINGREQUEST']._serialized_start=26
  _globals['_PINGREQUEST']._serialized_end=39
  _globals['_PINGRESPONSE']._serialized_start=41
  _globals['_PINGRESPONSE']._serialized_end=55
  _globals['_LOADMODELREQUEST']._serialized_start=57
  _globals['_LOADMODELREQUEST']._serialized_end=166
  _globals['_LOADMODELRESPONSE']._serialized_start=168
  _globals['_LOADMODELRESPONSE']._serialized_end=205
  _globals['_UNLOADMODELREQUEST']._serialized_start=207
  _globals['_UNLOADMODELREQUEST']._serialized_end=241
  _globals['_UNLOADMODELRESPONSE']._serialized_start=243
  _globals['_UNLOADMODELRESPONSE']._serialized_end=264
  _globals['_PREDICTREQUEST']._serialized_start=267
  _globals['_PREDICTREQUEST']._serialized_end=1039
  _globals['_PREDICTREQUEST_OPTIONS']._serialized_start=452
  _globals['_PREDICTREQUEST_OPTIONS']._serialized_end=1039
  _globals['_PREDICTRESPONSE']._serialized_start=1041
  _globals['_PREDICTRESPONSE']._serialized_end=1106
  _globals['_GETMODELSTATUSREQUEST']._serialized_start=1108
  _globals['_GETMODELSTATUSREQUEST']._serialized_end=1145
  _globals['_GETMODELSTATUSRESPONSE']._serialized_start=1147
  _globals['_GETMODELSTATUSRESPONSE']._serialized_end=1239
  _globals['_LISTMODELSREQUEST']._serialized_start=1241
  _globals['_LISTMODELSREQUEST']._serialized_end=1260
  _globals['_LISTMODELSRESPONSE']._serialized_start=1262
  _globals['_LISTMODELSRESPONSE']._serialized_end=1282
  _globals['_LLMSERVER']._serialized_start=1458
  _globals['_LLMSERVER']._serialized_end=1650
# @@protoc_insertion_point(module_scope)
